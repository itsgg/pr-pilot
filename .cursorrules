# PR-Pilot - Cursor AI Rules

## Project Context

You are helping build pr-pilot, an AI-powered PR review agent.
Tech: Node.js, ES modules, Octokit (GitHub API), Anthropic SDK (Claude API)
Goal: Ship a working MVP in 3 hours

## Code Style

- Modern ES modules (import/export)
- async/await (no callbacks, no .then)
- const over let, never var
- Template literals for strings
- Destructuring when clear
- 2-space indentation
- Max 100 chars per line
- Descriptive names (no abbreviations)

## Documentation

- JSDoc for ALL exported functions
- Include @param, @returns, @throws
- Explain WHY not WHAT for complex logic
- Example usage in comments for public APIs

## Error Handling

- try/catch around ALL API calls
- Descriptive error messages
- Include original error context
- Log errors to console.error
- Never silent failures

Example:

```javascript
try {
  const result = await apiCall();
  return result;
} catch (error) {
  console.error('[pr-pilot] API call failed:', error.message);
  throw new Error(`Failed to fetch data: ${error.message}`);
}
```

## API Clients

- Initialize once, reuse
- Use environment variables for secrets
- Log requests (redact tokens)
- Handle rate limits gracefully
- Add timeouts where supported

## Security

- NEVER log ANTHROPIC_API_KEY or GITHUB_TOKEN
- Validate all inputs
- Don't execute PR code
- Watch for prompt injection

## File Organization

- One major function/class per file
- Max 300 lines per file
- Use index.js for exports if needed
- Group related utilities

## Testing

### Unit Testing Requirements

- Write testable code (pure functions)
- Separate API calls from logic
- Make dependencies injectable
- Support --dry-run mode
- Use Node.js built-in test runner (no external dependencies)
- Test files: `*.test.js` alongside source files
- Mock all external APIs (GitHub, Anthropic)
- Test error scenarios and edge cases

### Test Structure

```javascript
// Example test file: agent/lib/config.test.js
import { describe, it, beforeEach, afterEach, mock } from 'node:test';
import { readFileSync } from 'node:fs';
import { loadConfig } from './config.js';

// Mock file system
mock.method(readFileSync, (path) => {
  if (path.includes('agent.yaml')) {
    return 'model: claude-sonnet-4-20250514\nmax_tokens: 4000';
  }
  throw new Error('File not found');
});

describe('Config Loader', () => {
  it('should load valid config', async () => {
    const config = await loadConfig('config/agent.yaml');
    assert.strictEqual(config.model, 'claude-sonnet-4-20250514');
    assert.strictEqual(config.max_tokens, 4000);
  });

  it('should throw on invalid config', async () => {
    await assert.rejects(
      () => loadConfig('invalid.yaml'),
      /Invalid configuration/
    );
  });
});
```

### Test Categories

1. **Unit Tests** - Test individual functions in isolation
   - Config loading and validation
   - Diff parsing and filtering
   - Cost estimation calculations
   - Comment formatting
   - JSON schema validation

2. **Integration Tests** - Test component interactions
   - GitHub client with mocked API
   - Claude client with mocked responses
   - End-to-end flow with dry-run mode

3. **Error Handling Tests** - Test all error scenarios
   - Invalid environment variables
   - API failures and timeouts
   - Invalid JSON responses
   - Cost cap exceeded
   - File filtering edge cases

### Mocking Strategy

- **GitHub API**: Mock Octokit responses with realistic data
- **Anthropic API**: Mock Claude responses with valid JSON
- **File System**: Mock file operations for config and metrics
- **Console**: Mock console methods to verify logging

### Test Data

- Use realistic test fixtures for PR diffs
- Include edge cases: binary files, large diffs, empty changes
- Test with various file types and patterns
- Mock responses match real API schemas

### Coverage Requirements

- Aim for 80%+ code coverage
- Test all exported functions
- Test all error paths
- Test configuration validation
- Test cost estimation accuracy

### Test Commands

```bash
# Run all tests
node --test

# Run specific test file
node --test agent/lib/config.test.js

# Run with coverage (if available)
node --test --experimental-test-coverage
```

### Test Organization

```text
agent/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ config.js
‚îÇ   ‚îú‚îÄ‚îÄ config.test.js
‚îÇ   ‚îú‚îÄ‚îÄ github-client.js
‚îÇ   ‚îú‚îÄ‚îÄ github-client.test.js
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ __fixtures__/
    ‚îú‚îÄ‚îÄ sample-pr-diff.txt
    ‚îú‚îÄ‚îÄ claude-response.json
    ‚îî‚îÄ‚îÄ config-valid.yaml
```

## GitHub Specifics

- Diff format: @@ -oldStart,oldCount +newStart,newCount @@
- API positions are relative to diff
- Handle added/deleted/modified files
- Validate paths before commenting

## Claude API Specifics

- Model: claude-sonnet-4-20250514
- Enforce JSON with explicit prompts
- Validate schema before use
- Estimate tokens before calling
- Retry once on JSON parse fail

## Logging

- Prefix: [pr-pilot]
- console.log for info
- console.error for errors
- console.warn for warnings
- Include timestamps

## Dependencies (locked)

- @octokit/rest (GitHub API)
- @anthropic-ai/sdk (Claude API)
- js-yaml (config)
- minimatch (globs)
- No others without approval.

## When Asked to Generate Code

- Ask clarifying questions
- Show usage examples
- Include error cases
- Suggest edge cases
- Add JSDoc comments
- Keep it simple (MVP mindset)

## Core Functionality Requirements

### JSON Response Contract

Claude must return ONLY valid JSON in this exact format:

```json
{
  "summary": "1-2 sentence overview of the PR",
  "issues": [
    {
      "path": "src/file.js",
      "line": 42,
      "category": "bug|style|security|perf|test",
      "severity": "low|med|high",
      "explanation": "Clear, actionable reason (1-2 sentences)",
      "fix_patch": "Suggested code fix (unified diff or code block)",
      "confidence": 0.85
    }
  ],
  "risks": ["Potential risk or concern about the changes"]
}
```

### File Filtering & Limits

- Exclude files matching glob patterns: `**/*.env`, `**/secrets/**`, `**/dist/**`, `**/node_modules/**`, `**/*.min.js`, `**/*.min.css`, `**/package-lock.json`, `**/yarn.lock`
- Respect max_files limit (default: 20)
- Send only changed hunks + minimal context (‚â§120 lines per file)

### Cost Management

- Estimate input tokens before API call (chars/4 approximation)
- Calculate cost using Claude Sonnet 4.5 pricing: Input $3/M tokens, Output $15/M tokens
- Abort if estimated cost exceeds cost_cap_usd (default: $0.50)
- Log cost estimation to console

### Comment Formatting

- Post inline comments for each issue with category emojis: üêõ bug, üíÖ style, üîí security, ‚ö° perf, üß™ test
- Format: `**[CATEGORY]** explanation\n\nSuggested fix:\n```\nfix_patch\n```\n\nConfidence: XX%`
- Post one summary comment on PR with overall assessment and risks

### Metrics Collection

Write to `/metrics/run.json` after each run with:

- timestamp, pr_number, time_to_first_feedback_sec
- num_comments_posted, est_cost_usd, truncated_due_to_limits
- files_reviewed, files_excluded

### Configuration Schema

Use `config/agent.yaml` with:

- model, max_tokens, cost_cap_usd, max_files, context_lines
- exclude_patterns (glob format)
- project metadata (name, description)
- team_rules (sent to Claude)

### Prompt Engineering

- System prompt: Role as senior code reviewer with strict JSON output rules
- User prompt: Project context + team rules + file diffs
- Enforce JSON output with explicit prompt instructions
- Retry once if JSON parsing fails

### CI/CD Requirements

- Trigger on pull_request events: opened, synchronize
- Run in GitHub Actions environment
- Access ANTHROPIC_API_KEY from repo secrets
- Access GITHUB_TOKEN (auto-provided by GitHub)

### Error Handling Requirements

Must handle:

- Invalid/missing environment variables ‚Üí Exit with clear error
- GitHub API failures ‚Üí Log and exit with error code
- Anthropic API failures ‚Üí Log and exit with error code
- Invalid JSON from Claude ‚Üí Retry once, then fail gracefully
- Cost cap exceeded ‚Üí Log reason and exit (not a failure)
- No files to review (all excluded) ‚Üí Log and exit successfully

### Security Requirements

- Never log secrets (redact ANTHROPIC_API_KEY and GITHUB_TOKEN)
- Validate inputs (PR numbers, file paths, config schema)
- Be aware of forked PR limitations
- Don't execute code from PR diffs
- Treat all PR content as untrusted input

### Project Structure

Follow the exact structure specified in REQUIREMENTS.md:

- `.github/workflows/pr-review.yml` (CI workflow)
- `agent/reviewer.js` (main entry point)
- `agent/lib/` (utility modules)
- `agent/prompts/review-prompt.js` (prompt templates)
- `config/agent.yaml` (configuration)
- `metrics/` (output directory)
